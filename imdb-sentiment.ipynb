{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10871548,"sourceType":"datasetVersion","datasetId":6754358}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:02:00.491865Z","iopub.execute_input":"2025-02-27T18:02:00.492212Z","iopub.status.idle":"2025-02-27T18:02:00.508891Z","shell.execute_reply.started":"2025-02-27T18:02:00.492180Z","shell.execute_reply":"2025-02-27T18:02:00.508212Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-sentiment/full_test_imdb.txt\n/kaggle/input/imdb-sentiment/full_train_imdb.txt\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"# Taking in input","metadata":{}},{"cell_type":"code","source":"reviews_train = []\nfor line in open('/kaggle/input/imdb-sentiment/full_test_imdb.txt', 'r', encoding=\"utf8\"):\n    reviews_train.append(line.strip())\n    \nreviews_test = []\nfor line in open('/kaggle/input/imdb-sentiment/full_train_imdb.txt', 'r', encoding=\"utf8\"):\n    reviews_test.append(line.strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:02:00.509876Z","iopub.execute_input":"2025-02-27T18:02:00.510138Z","iopub.status.idle":"2025-02-27T18:02:00.631508Z","shell.execute_reply.started":"2025-02-27T18:02:00.510119Z","shell.execute_reply":"2025-02-27T18:02:00.630647Z"}},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":"# Data Cleaning and Preprocessing","metadata":{}},{"cell_type":"code","source":"import re\n\nREPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\nREPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n\ndef preprocess_reviews(reviews):\n    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n    \n    return reviews\n\nreviews_train_clean = preprocess_reviews(reviews_train)\nreviews_test_clean = preprocess_reviews(reviews_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:02:00.633017Z","iopub.execute_input":"2025-02-27T18:02:00.633227Z","iopub.status.idle":"2025-02-27T18:02:04.744228Z","shell.execute_reply.started":"2025-02-27T18:02:00.633209Z","shell.execute_reply":"2025-02-27T18:02:04.743526Z"}},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":"## Vectorization","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer(binary=True)\ncv.fit(reviews_train_clean)\nX = cv.transform(reviews_train_clean)\nX_test = cv.transform(reviews_test_clean)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:02:04.745584Z","iopub.execute_input":"2025-02-27T18:02:04.745851Z","iopub.status.idle":"2025-02-27T18:02:15.582714Z","shell.execute_reply.started":"2025-02-27T18:02:04.745829Z","shell.execute_reply":"2025-02-27T18:02:15.581807Z"}},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":"## Starting baseline classifier model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\ntarget = [1 if i < 12500 else 0 for i in range(25000)]\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, target, train_size = 0.75\n)\n\nfor c in [0.01, 0.05, 0.25, 0.5, 1]:\n    \n    lr = LogisticRegression(C=c, solver='lbfgs', max_iter=5000)\n    lr.fit(X_train, y_train)\n    print (\"Accuracy for C=%s: %s\" \n           % (c, accuracy_score(y_val, lr.predict(X_val))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:02:15.583772Z","iopub.execute_input":"2025-02-27T18:02:15.584120Z","iopub.status.idle":"2025-02-27T18:02:29.568733Z","shell.execute_reply.started":"2025-02-27T18:02:15.584088Z","shell.execute_reply":"2025-02-27T18:02:29.567950Z"}},"outputs":[{"name":"stdout","text":"Accuracy for C=0.01: 0.87712\nAccuracy for C=0.05: 0.89104\nAccuracy for C=0.25: 0.89408\nAccuracy for C=0.5: 0.8928\nAccuracy for C=1: 0.8904\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"## Finalizing the model","metadata":{}},{"cell_type":"code","source":"final_model = LogisticRegression(C=0.05, solver='lbfgs', max_iter=5000)\nfinal_model.fit(X, target)\nprint (\"Final Accuracy: %s\" \n       % accuracy_score(target, final_model.predict(X_test)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:02:29.569868Z","iopub.execute_input":"2025-02-27T18:02:29.570220Z","iopub.status.idle":"2025-02-27T18:02:32.035059Z","shell.execute_reply.started":"2025-02-27T18:02:29.570187Z","shell.execute_reply":"2025-02-27T18:02:32.034234Z"}},"outputs":[{"name":"stdout","text":"Final Accuracy: 0.87968\n","output_type":"stream"}],"execution_count":54},{"cell_type":"markdown","source":"### Running a sanity test","metadata":{}},{"cell_type":"code","source":"feature_to_coef = {\n    word: coef for word, coef in zip(\n        cv.get_feature_names_out(), final_model.coef_[0]\n    )\n}\nfor best_positive in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1], \n    reverse=True)[:5]:\n    print (best_positive)\n        \nfor best_negative in sorted(\n    feature_to_coef.items(), \n    key=lambda x: x[1])[:5]:\n    print (best_negative)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:02:32.035951Z","iopub.execute_input":"2025-02-27T18:02:32.036253Z","iopub.status.idle":"2025-02-27T18:02:32.277174Z","shell.execute_reply.started":"2025-02-27T18:02:32.036230Z","shell.execute_reply":"2025-02-27T18:02:32.276461Z"}},"outputs":[{"name":"stdout","text":"('excellent', 0.9039371419166145)\n('hilarious', 0.7869229666130453)\n('amazing', 0.7716903255364735)\n('great', 0.7121650652025706)\n('perfect', 0.7045421508983317)\n('worst', -1.4331252589518797)\n('waste', -1.251499765671806)\n('awful', -1.0855116112674923)\n('terrible', -0.9759964494662143)\n('boring', -0.9010423701456618)\n","output_type":"stream"}],"execution_count":55},{"cell_type":"markdown","source":"# Text Processing","metadata":{}},{"cell_type":"markdown","source":"### Removing stop words with the help of NLTK (Natural Language Toolkit)","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('wordnet')\nfrom nltk.corpus import stopwords\n\nenglish_stop_words = stopwords.words('english')\ndef remove_stop_words(corpus):\n    removed_stop_words = []\n    for review in corpus:\n        removed_stop_words.append(\n            ' '.join([word for word in review.split() \n                      if word not in english_stop_words])\n        )\n    return removed_stop_words\n\nno_stop_words = remove_stop_words(reviews_train_clean)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:02:32.279472Z","iopub.execute_input":"2025-02-27T18:02:32.279695Z","iopub.status.idle":"2025-02-27T18:02:41.955074Z","shell.execute_reply.started":"2025-02-27T18:02:32.279677Z","shell.execute_reply":"2025-02-27T18:02:41.954374Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"### Normalization with Stemming","metadata":{}},{"cell_type":"code","source":"def get_stemmed_text(corpus):\n    from nltk.stem.porter import PorterStemmer\n    stemmer = PorterStemmer()\n    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n\nstemmed_reviews = get_stemmed_text(reviews_train_clean)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:02:41.956579Z","iopub.execute_input":"2025-02-27T18:02:41.956829Z","iopub.status.idle":"2025-02-27T18:04:00.281586Z","shell.execute_reply.started":"2025-02-27T18:02:41.956809Z","shell.execute_reply":"2025-02-27T18:04:00.280822Z"}},"outputs":[],"execution_count":57},{"cell_type":"markdown","source":"### Normalization with Lemmatization","metadata":{}},{"cell_type":"code","source":"#!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/\ndef get_lemmatized_text(corpus):\n    from nltk.stem import WordNetLemmatizer\n    lemmatizer = WordNetLemmatizer()\n    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n\nlemmatized_reviews = get_lemmatized_text(reviews_train_clean)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:04:00.283022Z","iopub.execute_input":"2025-02-27T18:04:00.283302Z","iopub.status.idle":"2025-02-27T18:04:16.708544Z","shell.execute_reply.started":"2025-02-27T18:04:00.283281Z","shell.execute_reply":"2025-02-27T18:04:16.707868Z"}},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":"#### Original","metadata":{}},{"cell_type":"code","source":"reviews_train_clean[0:3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:04:16.709332Z","iopub.execute_input":"2025-02-27T18:04:16.709553Z","iopub.status.idle":"2025-02-27T18:04:16.715044Z","shell.execute_reply.started":"2025-02-27T18:04:16.709535Z","shell.execute_reply":"2025-02-27T18:04:16.714220Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"['i went and saw this movie last night after being coaxed to by a few friends of mine ill admit that i was reluctant to see it because from what i knew of ashton kutcher he was only able to do comedy i was wrong kutcher played the character of jake fischer very well and kevin costner played ben randall with such professionalism the sign of a good movie is that it can toy with our emotions this one did exactly that the entire theater which was sold out was overcome by laughter during the first half of the movie and were moved to tears during the second half while exiting the theater i not only saw many women in tears but many full grown men as well trying desperately not to let anyone see them crying this movie was great and i suggest that you go see it before you judge',\n 'actor turned director bill paxton follows up his promising debut the gothic horror frailty with this family friendly sports drama about the 1913 us open where a young american caddy rises from his humble background to play against his bristish idol in what was dubbed as the greatest game ever played im no fan of golf and these scrappy underdog sports flicks are a dime a dozen most recently done to grand effect with miracle and cinderella man but some how this film was enthralling all the same the film starts with some creative opening credits imagine a disneyfied version of the animated opening credits of hbos carnivale and rome but lumbers along slowly for its first by the numbers hour once the action moves to the us open things pick up very well paxton does a nice job and shows a knack for effective directorial flourishes i loved the rain soaked montage of the action on day two of the open that propel the plot further or add some unexpected psychological depth to the proceedings theres some compelling character development when the british harry vardon is haunted by images of the aristocrats in black suits and top hats who destroyed his family cottage as a child to make way for a golf course he also does a good job of visually depicting what goes on in the players heads under pressure golf a painfully boring sport is brought vividly alive here credit should also be given the set designers and costume department for creating an engaging period piece atmosphere of london and boston at the beginning of the twentieth century you know how this is going to end not only because its based on a true story but also because films in this genre follow the same template over and over but paxton puts on a better than average show and perhaps indicates more talent behind the camera than he ever had in front of it despite the formulaic nature this is a nice and easy film to root for that deserves to find an audience',\n 'as a recreational golfer with some knowledge of the sports history i was pleased with disneys sensitivity to the issues of class in golf in the early twentieth century the movie depicted well the psychological battles that harry vardon fought within himself from his childhood trauma of being evicted to his own inability to break that glass ceiling that prevents him from being accepted as an equal in english golf society likewise the young ouimet goes through his own class struggles being a mere caddie in the eyes of the upper crust americans who scoff at his attempts to rise above his standing  what i loved best however is how this theme of class is manifested in the characters of ouimets parents his father is a working class drone who sees the value of hard work but is intimidated by the upper class his mother however recognizes her sons talent and desire and encourages him to pursue his dream of competing against those who think he is inferior finally the golf scenes are well photographed although the course used in the movie was not the actual site of the historical tournament the little liberties taken by disney do not detract from the beauty of the film theres one little disney moment at the pool table otherwise the viewer does not really think disney the ending as in miracle is not some disney creation but one that only human history could have written']"},"metadata":{}}],"execution_count":59},{"cell_type":"markdown","source":"#### Stemmed","metadata":{}},{"cell_type":"code","source":"stemmed_reviews[0:3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:04:16.715888Z","iopub.execute_input":"2025-02-27T18:04:16.716114Z","iopub.status.idle":"2025-02-27T18:04:16.728767Z","shell.execute_reply.started":"2025-02-27T18:04:16.716095Z","shell.execute_reply":"2025-02-27T18:04:16.728021Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"['i went and saw thi movi last night after be coax to by a few friend of mine ill admit that i wa reluct to see it becaus from what i knew of ashton kutcher he wa onli abl to do comedi i wa wrong kutcher play the charact of jake fischer veri well and kevin costner play ben randal with such profession the sign of a good movi is that it can toy with our emot thi one did exactli that the entir theater which wa sold out wa overcom by laughter dure the first half of the movi and were move to tear dure the second half while exit the theater i not onli saw mani women in tear but mani full grown men as well tri desper not to let anyon see them cri thi movi wa great and i suggest that you go see it befor you judg',\n 'actor turn director bill paxton follow up hi promis debut the gothic horror frailti with thi famili friendli sport drama about the 1913 us open where a young american caddi rise from hi humbl background to play against hi bristish idol in what wa dub as the greatest game ever play im no fan of golf and these scrappi underdog sport flick are a dime a dozen most recent done to grand effect with miracl and cinderella man but some how thi film wa enthral all the same the film start with some creativ open credit imagin a disneyfi version of the anim open credit of hbo carnival and rome but lumber along slowli for it first by the number hour onc the action move to the us open thing pick up veri well paxton doe a nice job and show a knack for effect directori flourish i love the rain soak montag of the action on day two of the open that propel the plot further or add some unexpect psycholog depth to the proceed there some compel charact develop when the british harri vardon is haunt by imag of the aristocrat in black suit and top hat who destroy hi famili cottag as a child to make way for a golf cours he also doe a good job of visual depict what goe on in the player head under pressur golf a pain bore sport is brought vividli aliv here credit should also be given the set design and costum depart for creat an engag period piec atmospher of london and boston at the begin of the twentieth centuri you know how thi is go to end not onli becaus it base on a true stori but also becaus film in thi genr follow the same templat over and over but paxton put on a better than averag show and perhap indic more talent behind the camera than he ever had in front of it despit the formula natur thi is a nice and easi film to root for that deserv to find an audienc',\n 'as a recreat golfer with some knowledg of the sport histori i wa pleas with disney sensit to the issu of class in golf in the earli twentieth centuri the movi depict well the psycholog battl that harri vardon fought within himself from hi childhood trauma of be evict to hi own inabl to break that glass ceil that prevent him from be accept as an equal in english golf societi likewis the young ouimet goe through hi own class struggl be a mere caddi in the eye of the upper crust american who scoff at hi attempt to rise abov hi stand what i love best howev is how thi theme of class is manifest in the charact of ouimet parent hi father is a work class drone who see the valu of hard work but is intimid by the upper class hi mother howev recogn her son talent and desir and encourag him to pursu hi dream of compet against those who think he is inferior final the golf scene are well photograph although the cours use in the movi wa not the actual site of the histor tournament the littl liberti taken by disney do not detract from the beauti of the film there one littl disney moment at the pool tabl otherwis the viewer doe not realli think disney the end as in miracl is not some disney creation but one that onli human histori could have written']"},"metadata":{}}],"execution_count":60},{"cell_type":"markdown","source":"#### Lemmatized","metadata":{}},{"cell_type":"code","source":"lemmatized_reviews[0:3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:04:16.729552Z","iopub.execute_input":"2025-02-27T18:04:16.729841Z","iopub.status.idle":"2025-02-27T18:04:16.743027Z","shell.execute_reply.started":"2025-02-27T18:04:16.729809Z","shell.execute_reply":"2025-02-27T18:04:16.742242Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"['i went and saw this movie last night after being coaxed to by a few friend of mine ill admit that i wa reluctant to see it because from what i knew of ashton kutcher he wa only able to do comedy i wa wrong kutcher played the character of jake fischer very well and kevin costner played ben randall with such professionalism the sign of a good movie is that it can toy with our emotion this one did exactly that the entire theater which wa sold out wa overcome by laughter during the first half of the movie and were moved to tear during the second half while exiting the theater i not only saw many woman in tear but many full grown men a well trying desperately not to let anyone see them cry this movie wa great and i suggest that you go see it before you judge',\n 'actor turned director bill paxton follows up his promising debut the gothic horror frailty with this family friendly sport drama about the 1913 u open where a young american caddy rise from his humble background to play against his bristish idol in what wa dubbed a the greatest game ever played im no fan of golf and these scrappy underdog sport flick are a dime a dozen most recently done to grand effect with miracle and cinderella man but some how this film wa enthralling all the same the film start with some creative opening credit imagine a disneyfied version of the animated opening credit of hbos carnivale and rome but lumber along slowly for it first by the number hour once the action move to the u open thing pick up very well paxton doe a nice job and show a knack for effective directorial flourish i loved the rain soaked montage of the action on day two of the open that propel the plot further or add some unexpected psychological depth to the proceeding there some compelling character development when the british harry vardon is haunted by image of the aristocrat in black suit and top hat who destroyed his family cottage a a child to make way for a golf course he also doe a good job of visually depicting what go on in the player head under pressure golf a painfully boring sport is brought vividly alive here credit should also be given the set designer and costume department for creating an engaging period piece atmosphere of london and boston at the beginning of the twentieth century you know how this is going to end not only because it based on a true story but also because film in this genre follow the same template over and over but paxton put on a better than average show and perhaps indicates more talent behind the camera than he ever had in front of it despite the formulaic nature this is a nice and easy film to root for that deserves to find an audience',\n 'a a recreational golfer with some knowledge of the sport history i wa pleased with disney sensitivity to the issue of class in golf in the early twentieth century the movie depicted well the psychological battle that harry vardon fought within himself from his childhood trauma of being evicted to his own inability to break that glass ceiling that prevents him from being accepted a an equal in english golf society likewise the young ouimet go through his own class struggle being a mere caddie in the eye of the upper crust american who scoff at his attempt to rise above his standing what i loved best however is how this theme of class is manifested in the character of ouimets parent his father is a working class drone who see the value of hard work but is intimidated by the upper class his mother however recognizes her son talent and desire and encourages him to pursue his dream of competing against those who think he is inferior finally the golf scene are well photographed although the course used in the movie wa not the actual site of the historical tournament the little liberty taken by disney do not detract from the beauty of the film there one little disney moment at the pool table otherwise the viewer doe not really think disney the ending a in miracle is not some disney creation but one that only human history could have written']"},"metadata":{}}],"execution_count":61},{"cell_type":"markdown","source":"### Ngram","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\nngram_vectorizer.fit(reviews_train_clean)\nX = ngram_vectorizer.transform(reviews_train_clean)\nX_test = ngram_vectorizer.transform(reviews_test_clean)\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, target, train_size = 0.75\n)\n\nfor c in [0.01, 0.05, 0.25, 0.5, 1]:\n    \n    lr = LogisticRegression(C=c, solver='lbfgs', max_iter=5000)\n    lr.fit(X_train, y_train)\n    print (\"Accuracy for C=%s: %s\" \n           % (c, accuracy_score(y_val, lr.predict(X_val))))\n        \nfinal_ngram = LogisticRegression(C=0.5, solver='lbfgs', max_iter=5000)\nfinal_ngram.fit(X, target)\nprint (\"Final Accuracy: %s\" \n       % accuracy_score(target, final_ngram.predict(X_test)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:04:16.743911Z","iopub.execute_input":"2025-02-27T18:04:16.744174Z","iopub.status.idle":"2025-02-27T18:07:09.484575Z","shell.execute_reply.started":"2025-02-27T18:04:16.744141Z","shell.execute_reply":"2025-02-27T18:07:09.483694Z"}},"outputs":[{"name":"stdout","text":"Accuracy for C=0.01: 0.88896\nAccuracy for C=0.05: 0.89568\nAccuracy for C=0.25: 0.89872\nAccuracy for C=0.5: 0.89888\nAccuracy for C=1: 0.89776\nFinal Accuracy: 0.89556\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"## Building up Vectors","metadata":{}},{"cell_type":"markdown","source":"#### Word count","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nwc_vectorizer = CountVectorizer(binary=False)\nwc_vectorizer.fit(reviews_train_clean)\nX = wc_vectorizer.transform(reviews_train_clean)\nX_test = wc_vectorizer.transform(reviews_test_clean)\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, target, train_size = 0.75, \n)\n\nfor c in [0.01, 0.05, 0.25, 0.5, 1]:\n    \n    lr = LogisticRegression(C=c, solver='lbfgs', max_iter=5000)\n    lr.fit(X_train, y_train)\n    print (\"Accuracy for C=%s: %s\" \n           % (c, accuracy_score(y_val, lr.predict(X_val))))\n        \nfinal_wc = LogisticRegression(C=0.05, solver='lbfgs', max_iter=5000)\nfinal_wc.fit(X, target)\nprint (\"Final Accuracy: %s\" \n       % accuracy_score(target, final_wc.predict(X_test)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:07:09.485468Z","iopub.execute_input":"2025-02-27T18:07:09.485714Z","iopub.status.idle":"2025-02-27T18:08:17.119000Z","shell.execute_reply.started":"2025-02-27T18:07:09.485694Z","shell.execute_reply":"2025-02-27T18:08:17.118218Z"}},"outputs":[{"name":"stdout","text":"Accuracy for C=0.01: 0.88896\nAccuracy for C=0.05: 0.89424\nAccuracy for C=0.25: 0.89072\nAccuracy for C=0.5: 0.8904\nAccuracy for C=1: 0.89056\nFinal Accuracy: 0.87848\n","output_type":"stream"}],"execution_count":63},{"cell_type":"markdown","source":"#### TF-IDF","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\ntfidf_vectorizer = TfidfVectorizer()\ntfidf_vectorizer.fit(reviews_train_clean)\nX = tfidf_vectorizer.transform(reviews_train_clean)\nX_test = tfidf_vectorizer.transform(reviews_test_clean)\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, target, train_size = 0.75\n)\n\nfor c in [0.01, 0.05, 0.25, 0.5, 1]:\n    \n    lr = LogisticRegression(C=c, solver='lbfgs', max_iter=5000)\n    lr.fit(X_train, y_train)\n    print (\"Accuracy for C=%s: %s\" \n           % (c, accuracy_score(y_val, lr.predict(X_val))))\n \nfinal_tfidf = LogisticRegression(C=1, solver='lbfgs', max_iter=5000)\nfinal_tfidf.fit(X, target)\nprint (\"Final Accuracy: %s\" \n       % accuracy_score(target, final_tfidf.predict(X_test)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:08:17.119610Z","iopub.execute_input":"2025-02-27T18:08:17.119893Z","iopub.status.idle":"2025-02-27T18:08:34.406013Z","shell.execute_reply.started":"2025-02-27T18:08:17.119860Z","shell.execute_reply":"2025-02-27T18:08:34.405176Z"}},"outputs":[{"name":"stdout","text":"Accuracy for C=0.01: 0.7984\nAccuracy for C=0.05: 0.8384\nAccuracy for C=0.25: 0.87696\nAccuracy for C=0.5: 0.88736\nAccuracy for C=1: 0.89216\nFinal Accuracy: 0.87944\n","output_type":"stream"}],"execution_count":64},{"cell_type":"markdown","source":"### Trying model using Support Vector Machines (SVM)\n","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\nngram_vectorizer.fit(reviews_train_clean)\nX = ngram_vectorizer.transform(reviews_train_clean)\nX_test = ngram_vectorizer.transform(reviews_test_clean)\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, target, train_size = 0.75\n)\n\nfor c in [0.01, 0.05, 0.25, 0.5, 1]:\n    \n    svm = LinearSVC(C=c, max_iter=5000)\n    svm.fit(X_train, y_train)\n    print (\"Accuracy for C=%s: %s\" \n           % (c, accuracy_score(y_val, svm.predict(X_val))))\n        \nfinal_svm_ngram = LinearSVC(C=0.01, max_iter=5000)\nfinal_svm_ngram.fit(X, target)\nprint (\"Final Accuracy: %s\" \n       % accuracy_score(target, final_svm_ngram.predict(X_test)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T18:08:34.406829Z","iopub.execute_input":"2025-02-27T18:08:34.407141Z","iopub.status.idle":"2025-02-27T18:10:36.645832Z","shell.execute_reply.started":"2025-02-27T18:08:34.407113Z","shell.execute_reply":"2025-02-27T18:10:36.644857Z"}},"outputs":[{"name":"stdout","text":"Accuracy for C=0.01: 0.89728\nAccuracy for C=0.05: 0.8944\nAccuracy for C=0.25: 0.8928\nAccuracy for C=0.5: 0.89248\nAccuracy for C=1: 0.89248\nFinal Accuracy: 0.89512\n","output_type":"stream"}],"execution_count":65},{"cell_type":"markdown","source":"## Final Model using GridCV and ensemble of models","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.metrics import accuracy_score\n\nstop_words = ['in', 'of', 'at', 'a', 'the', 'is', 'and', 'it', 'to', 'this', 'that', 'with', 'for', 'on', 'you', 'was']\ntfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3), stop_words=stop_words, \n                                   sublinear_tf=True, max_features=500000)\ntfidf_vectorizer.fit(reviews_train_clean)\nX = tfidf_vectorizer.transform(reviews_train_clean)\nX_test = tfidf_vectorizer.transform(reviews_test_clean)\n\nX_train, X_val, y_train, y_val = train_test_split(X, target, train_size=0.75, stratify=target, random_state=42)\n\nparam_grid = {'C': [0.001, 0.005, 0.01, 0.05, 0.1, 1, 5, 10, 20, 50]}\ngrid_search = GridSearchCV(LinearSVC(max_iter=5000, dual=False), param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\ngrid_search.fit(X_train, y_train)\nbest_svm = grid_search.best_estimator_\nprint(f\"Best C for LinearSVC: {grid_search.best_params_['C']}\")\n\nsgd_svm = SGDClassifier(loss='hinge', max_iter=2000, tol=1e-4, n_jobs=-1)\nsgd_svm.fit(X_train, y_train)\n\nlogreg = LogisticRegression(penalty='l2', solver='saga', max_iter=2000, n_jobs=-1)\nlogreg.fit(X_train, y_train)\n\nstacking = StackingClassifier(estimators=[('svm', best_svm), ('sgd', sgd_svm), ('logreg', logreg)], \n                              final_estimator=LogisticRegression(max_iter=2000, n_jobs=-1), n_jobs=-1, verbose=1)\nstacking.fit(X_train, y_train)\n\nmodels = {'LinearSVC': best_svm, 'SGD SVM': sgd_svm, 'LogReg': logreg, 'Stacking': stacking}\n\nfor name, model in models.items():\n    y_pred = model.predict(X_val)\n    acc = accuracy_score(y_val, y_pred)\n    print(f\"{name} Validation Accuracy: {acc:.5f}\")\n\nfinal_accuracy = accuracy_score(target, stacking.predict(X_test))\nprint(f\"Final Accuracy (Stacking Model): {final_accuracy:.5f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T19:45:04.597292Z","iopub.execute_input":"2025-02-27T19:45:04.597618Z","iopub.status.idle":"2025-02-27T19:48:38.757405Z","shell.execute_reply.started":"2025-02-27T19:45:04.597593Z","shell.execute_reply":"2025-02-27T19:48:38.756260Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 10 candidates, totalling 50 fits\nBest C for LinearSVC: 1\nLinearSVC Validation Accuracy: 0.92384\nSGD SVM Validation Accuracy: 0.91648\nLogReg Validation Accuracy: 0.90640\nStacking Validation Accuracy: 0.92480\nFinal Accuracy (Stacking Model): 0.90112\n","output_type":"stream"}],"execution_count":77}]}